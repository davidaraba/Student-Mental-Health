# üß† Predicting Student Depression: A Big Data Analytics Approach with Apache Spark

[![Python](https://img.shields.io/badge/Python-3.x-blue.svg)](https://python.org)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-4.0.1-orange.svg)](https://spark.apache.org)
[![PySpark](https://img.shields.io/badge/PySpark-MLlib-green.svg)](https://spark.apache.org/docs/latest/ml-guide.html)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **A comprehensive machine learning pipeline leveraging Apache Spark to predict student depression and identify at-risk populations through advanced analytics on academic, lifestyle, and demographic factors.**

## üéØ Project Overview

This project addresses one of the most pressing challenges in modern education: **student mental health**. By analyzing a comprehensive dataset of 27,901 students across India, I've developed a scalable machine learning framework that can identify students at risk of depression and provide actionable insights for early intervention.

### üåü Key Achievements

- **92.3% AUC Score** in depression prediction using Logistic Regression
- **88.24% Recall Rate** ensuring minimal false negatives in critical mental health screening
- **4 Distinct Student Profiles** identified through advanced clustering analysis
- **Scalable Architecture** capable of processing millions of student records
- **Actionable Insights** revealing strong correlations between stress factors and mental health outcomes

## üöÄ Why This Matters

Student mental health is a **global crisis**. According to recent studies:

- 60% of college students report overwhelming anxiety
- 40% experience severe depression
- Suicide is the second leading cause of death among college students

This project demonstrates how **big data technologies** can transform reactive mental health support into **proactive, data-driven interventions**.

## üèóÔ∏è Technical Architecture

### System Design

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Data Sources  ‚îÇ    ‚îÇ  Cloud Storage  ‚îÇ    ‚îÇ  Apache Spark   ‚îÇ    ‚îÇ  ML Pipeline    ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ Student Info  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Google Cloud  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Data Ingestion‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Classification‚îÇ
‚îÇ ‚Ä¢ Academic Data ‚îÇ    ‚îÇ ‚Ä¢ Storage (GCS) ‚îÇ    ‚îÇ ‚Ä¢ Preprocessing ‚îÇ    ‚îÇ ‚Ä¢ Regression    ‚îÇ
‚îÇ ‚Ä¢ Lifestyle     ‚îÇ    ‚îÇ ‚Ä¢ Local Files   ‚îÇ    ‚îÇ ‚Ä¢ Feature Eng.  ‚îÇ    ‚îÇ ‚Ä¢ Clustering    ‚îÇ
‚îÇ ‚Ä¢ Mental Health ‚îÇ    ‚îÇ ‚Ä¢ Hybrid Mode   ‚îÇ    ‚îÇ ‚Ä¢ ML Training   ‚îÇ    ‚îÇ ‚Ä¢ Association   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Technology Stack

- **Core Engine**: Apache Spark 4.0.1 with PySpark
- **Machine Learning**: Spark MLlib (Logistic Regression, Linear Regression, K-Means, FPGrowth)
- **Data Processing**: Distributed computing for 27K+ student records
- **Cloud Storage**: Google Cloud Storage (GCS) for scalable data storage and access
- **Visualization**: Matplotlib, Seaborn for comprehensive data insights
- **Languages**: Python 3.x with advanced data science libraries

## üìä Dataset Overview

### Data Source

This project utilizes the **Student Depression Dataset** from Kaggle, a comprehensive collection of student mental health data from across India. The dataset provides a rich foundation for understanding the complex interplay between academic, lifestyle, and mental health factors.

**Dataset Reference**: [Student Depression Dataset](https://www.kaggle.com/datasets/adilshamim8/student-depression-dataset) by Adil Shamim on Kaggle

### Dataset Composition

Our comprehensive dataset includes **27,901 student records** across four integrated data sources:

| Dataset                  | Records | Key Features                                         | Sample Variables                                       |
| ------------------------ | ------- | ---------------------------------------------------- | ------------------------------------------------------ |
| **Student Info**   | 27,901  | Demographics, Location, Academic Level               | Gender, Age, City, Profession, Degree                  |
| **Academic Data**  | 27,901  | CGPA, Academic Pressure, Study Satisfaction          | CGPA, Academic Pressure, Work/Study Hours              |
| **Lifestyle Data** | 27,901  | Sleep Patterns, Diet, Financial Stress               | Sleep Duration, Dietary Habits, Financial Stress       |
| **Mental Health**  | 27,901  | Depression Status, Suicidal Thoughts, Family History | Depression (Binary), Suicidal Thoughts, Family History |

### Data Characteristics

- **Total Features**: 18 comprehensive variables spanning demographic, academic, lifestyle, and mental health dimensions
- **Geographic Coverage**: Students from major Indian cities including Bangalore, Mumbai, Delhi, Chennai, and others
- **Academic Diversity**: Various degree programs from undergraduate to PhD levels
- **Mental Health Indicators**: Binary depression classification with supporting risk factors
- **Data Quality**: High-quality dataset with minimal missing values (only 3 missing values in Financial Stress)

### Key Data Insights

- **Class Distribution**: Moderate imbalance with ~58% of students classified as depressed
- **Age Range**: Primarily 18-35 years, representing typical student demographics
- **Geographic Patterns**: Significant regional variations in mental health outcomes
- **Academic Performance**: CGPA distribution shows distinct peaks at integer values (7.0, 7.5, 8.0)
- **Stress Factors**: Academic and financial stress show strong correlations with mental health outcomes

### Data Preprocessing & Methodology

The dataset underwent comprehensive preprocessing to ensure optimal model performance:

- **Data Integration**: Four separate CSV files merged using inner joins on student ID
- **Type Correction**: Automatic schema inference with manual correction for numerical columns containing placeholder values
- **Missing Value Handling**: Mean imputation for the 3 missing Financial Stress values
- **Feature Engineering**: Categorical variables encoded using StringIndexer and OneHotEncoder
- **Feature Assembly**: All features combined into a single vector using VectorAssembler for Spark MLlib compatibility
- **Data Splitting**: 80/20 train-test split with fixed random seed for reproducibility

## üî¨ Machine Learning Pipeline

### 1. Classification: Depression Prediction

- **Algorithm**: Logistic Regression with Spark MLlib
- **Performance**: 92.3% AUC, 88.24% Recall, 84.51% Accuracy
- **Impact**: Identifies students at risk with minimal false negatives

### 2. Regression: Academic Performance Analysis

- **Algorithm**: Linear Regression
- **Target**: CGPA prediction
- **Insight**: Academic performance poorly predicted by lifestyle factors (R¬≤ = 0.0168)

### 3. Clustering: Student Profile Segmentation

- **Algorithm**: K-Means with Elbow Method optimization
- **Clusters**: 4 distinct student profiles identified
- **Key Finding**: Clear separation between "At-Risk" and "Resilient" student groups

### 4. Association Rule Mining: Pattern Discovery

- **Algorithm**: FPGrowth
- **Discovery**: Strong associations between high stress and suicidal thoughts
- **Confidence**: 75.4% for academic pressure ‚Üí suicidal thoughts

## üéØ Key Findings & Insights

### Critical Risk Factors Identified

1. **Geographic Location**: Specific cities show significantly higher depression rates
2. **Academic Pressure**: Students with high academic stress are 19% more likely to have suicidal thoughts
3. **Financial Stress**: Strong correlation with both depression and suicidal ideation
4. **Family History**: 5% increase in depression rate among students with family mental health history

### Student Profile Analysis

- **At-Risk Groups**: High academic/financial stress, 69% depression rate
- **Resilient Groups**: Lower stress levels, 42-49% depression rate
- **Academic Performance**: CGPA shows minimal correlation with mental health factors

## üõ†Ô∏è Installation & Setup

### Prerequisites

```bash
# Python 3.8+
# Java 8+ (required for Spark)
# 8GB+ RAM recommended for optimal performance
```

### Quick Start

```bash
# Clone the repository
git clone https://github.com/yourusername/student-mental-health-prediction.git
cd student-mental-health-prediction

# Create virtual environment
python -m venv smh_env
source smh_env/bin/activate  # On Windows: smh_env\Scripts\activate

# Install dependencies
pip install pyspark pandas matplotlib seaborn numpy jupyter

# For Google Cloud Storage support (optional)
pip install google-cloud-storage

# Launch Jupyter Notebook
jupyter notebook notebooks/smh.ipynb
```

## üõ†Ô∏è Setup on Google Cloud VM (for Demonstration)

These instructions detail how to set up the Google Cloud Platform (GCP) environment used for developing and demonstrating this project, ensuring reproducibility as requested by the course marking criteria.

### 1. Create the Compute Engine VM Instance

Create a VM instance in the GCP Console with the following specifications:

- **Name:** `infs3208-smh` (or similar)
- **Region:** `australia-southeast1` (Sydney)
- **Machine type:** Series **E2**, type **e2-standard-4** (4 vCPUs, 16 GB memory)
- **Boot disk:** OS **Debian 11 (bullseye)**, Size **30 GB**
- **Firewall:** Allow **HTTP** and **HTTPS** traffic
- **Access Scopes (IMPORTANT):** Set to **"Allow full access to all Cloud APIs"**. This grants the VM the necessary permissions to interact with other GCP services like Cloud Storage.

### 2. Connect via SSH and Install Software

Connect to the newly created VM via the browser SSH provided in the GCP console and run the following commands:

```bash
# Update package lists
sudo apt-get update

# Download and install Miniconda (Python environment manager)
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/miniconda
export PATH="$HOME/miniconda/bin:$PATH"

# Install Git (version control)
sudo apt-get install git -y

# Install Java 17 (Required by Spark 4.x)
sudo apt-get install -y openjdk-17-jdk

# IMPORTANT: Close and reopen the SSH terminal window now
# This ensures the new PATH for conda is recognized in the next steps.
```

### 3. Initialize Conda and Set JAVA_HOME

After reopening the SSH terminal, initialize Conda and permanently set the `JAVA_HOME` environment variable:

```bash
# Initialize Conda for the bash shell
~/miniconda/bin/conda init bash

# Add JAVA_HOME setting to the bash startup file
echo 'export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64' >> ~/.bashrc

# IMPORTANT: Close and reopen the SSH terminal window again
# This ensures the .bashrc changes (conda init and JAVA_HOME) take effect.
```

### 4. Clone Project and Set Up Environment

Navigate to your home directory, clone the project repository, and create the Conda environment using the provided `requirements.txt` file:

```bash
# Go to home directory (if not already there)
cd ~

# Clone the repository
git clone https://github.com/davidaraba/Student-Mental-Health.git

# Navigate into the project directory
cd Student-Mental-Health

# Accept Conda Terms of Service (run these two commands)
conda config --set channel_priority strict
conda config --append channels conda-forge
conda config --set experimental_solver libmamba
conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main
conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r


# Create the Conda environment
conda create -n smh python=3.10 -y

# Activate the environment
conda activate smh

# Install all required packages
pip install -r requirements.txt
```

### 5. Configure Git Identity (One-Time Setup)

Configure Git with your name and email for making commits:

```bash
git config --global user.name "[Your Name]"
git config --global user.email "[Your Email]"
```

### 6. Grant Storage Permissions (Troubleshooting Step)

If you encounter permission errors (HTTP 403) when the notebook tries to read from GCS, explicitly grant the VM's service account the necessary role on your bucket:

1. Find the VM's service account email (e.g., `NUMBER-compute@developer.gserviceaccount.com`) on the VM details page in the GCP Console.
2. Go to your GCS bucket (`david-araba-infs3208-data`) -> **Permissions** tab -> **Grant Access**.
3. Add the service account email as a **New principal**.
4. Assign the role **`Cloud Storage` -> `Storage Object Viewer`**.
5. Save and wait ~2 minutes for permissions to propagate.

### 7. Run Jupyter Notebook

Finally, start the Jupyter Notebook server:

```bash
# Ensure you are in the project directory (~/Student-Mental-Health)
# Ensure the (smh) environment is active

jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser
```

Access the notebook from your local browser using the VM's **External IP** address and the **token** provided in the terminal output (e.g., `http://<VM_EXTERNAL_IP>:8888/?token=...`). Set `USE_GCS = True` in the notebook to run using cloud data for the demonstration.

### Spark Configuration

#### Local Development

```python
# Initialize Spark Session for local development
spark = SparkSession.builder \
    .appName("StudentMentalHealthPrediction") \
    .config("spark.sql.adaptive.enabled", "true") \
    .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
    .getOrCreate()
```

#### Google Cloud Storage Configuration

```python
# Initialize Spark Session with GCS support
spark = SparkSession.builder \
    .appName("StudentMentalHealthPrediction") \
    .config("spark.jars.packages", "com.google.cloud.bigdataoss:gcs-connector:hadoop3-2.2.20") \
    .config("spark.hadoop.fs.gs.impl", "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem") \
    .config("spark.hadoop.fs.AbstractFileSystem.gs.impl", "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS") \
    .config("spark.hadoop.google.cloud.auth.type", "APPLICATION_DEFAULT_CREDENTIALS") \
    .getOrCreate()
```

### Google Cloud Storage Setup

#### Prerequisites for GCS

1. **Google Cloud Account**: Create a Google Cloud Platform account
2. **Authentication**: Set up application default credentials
3. **Bucket Creation**: Create a GCS bucket for your data

#### Authentication Setup

```bash
# Install Google Cloud CLI
curl https://sdk.cloud.google.com | bash
exec -l $SHELL

# Authenticate with Google Cloud
gcloud auth application-default login

# Set your project ID
gcloud config set project YOUR_PROJECT_ID
```

#### Data Loading Options

The project supports **flexible data loading** with a simple configuration switch:

```python
# Configuration switch in the notebook
USE_GCS = True  # Set to True for Google Cloud Storage
USE_GCS = False # Set to False for local files

# Automatic path resolution
if USE_GCS:
    bucket_name = "your-bucket-name"
    base_path = f'gs://{bucket_name}/'
    print(f"‚úÖ Reading data from Google Cloud Storage bucket: {bucket_name}")
else:
    base_path = "../data/"
    print("‚úÖ Reading data from local '../data/' directory.")
```

#### Benefits of Google Cloud Storage Integration

- **Scalability**: Handle datasets of any size without local storage constraints
- **Collaboration**: Share data across team members and environments
- **Performance**: Optimized data access for distributed computing
- **Cost-Effective**: Pay only for storage and compute resources used
- **Security**: Enterprise-grade security and access controls

#### Troubleshooting GCS Issues

If you encounter issues with Google Cloud Storage integration:

1. **Authentication Errors**:

   ```bash
   # Re-authenticate with Google Cloud
   gcloud auth application-default login
   ```
2. **Bucket Access Issues**:

   - Verify bucket name is correct
   - Check bucket permissions
   - Ensure files exist in the bucket
3. **Connection Timeouts**:

   - Check internet connectivity
   - Verify firewall settings
   - Review Google Cloud quotas
4. **File Not Found Errors**:

   - Confirm file paths in bucket
   - Check file naming conventions
   - Verify file uploads completed successfully

## üìà Performance Metrics

### Model Performance Summary

| Model                         | Metric     | Score  | Interpretation                   |
| ----------------------------- | ---------- | ------ | -------------------------------- |
| **Logistic Regression** | AUC-ROC    | 92.30% | Excellent discriminative ability |
| **Logistic Regression** | Recall     | 88.24% | Minimal false negatives          |
| **Logistic Regression** | F1-Score   | 86.69% | Well-balanced performance        |
| **Linear Regression**   | R¬≤        | 1.68%  | Poor CGPA predictability         |
| **K-Means**             | Silhouette | 0.349  | Fair cluster separation          |

### Scalability Benchmarks

- **Data Processing**: 27,901 records processed in <30 seconds
- **Model Training**: All 4 models trained in <2 minutes
- **Memory Usage**: Optimized for distributed computing
- **Scalability**: Architecture supports 1M+ student records

## üîç Deep Dive Analysis

### Feature Importance Analysis

The model identified **geographic location** as the strongest predictor of depression, revealing significant regional disparities in student mental health outcomes.

### Stress-Depression Correlation

Our analysis revealed a **stark correlation** between stress levels and depression:

- Depressed students: 3.7/5 average academic pressure
- Non-depressed students: 2.4/5 average academic pressure

### Association Rules Discovery

**High-Confidence Rules Identified:**

- `High Academic Pressure` ‚Üí `Suicidal Thoughts` (75.4% confidence, 1.19 lift)
- `High Financial Stress` ‚Üí `Suicidal Thoughts` (72.9% confidence, 1.15 lift)

## üöÄ Future Enhancements

### Immediate Opportunities

- **Real-time Deployment**: Web application for student wellness screening
- **Advanced Models**: Gradient Boosting, Random Forest, Neural Networks
- **Feature Engineering**: Social media sentiment, attendance patterns
- **Integration**: University information systems for automated monitoring

### Long-term Vision

- **Predictive Analytics**: Early warning system for at-risk students
- **Intervention Strategies**: Personalized support recommendations
- **Policy Impact**: Data-driven mental health policy development
- **Global Expansion**: Multi-institutional, multi-country analysis

## üìö Technical Documentation

### Code Structure

```
SMH/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ smh.ipynb          # Main analysis notebook with GCS integration
‚îú‚îÄ‚îÄ data/                  # Local data storage (optional)
‚îÇ   ‚îú‚îÄ‚îÄ student_info.csv   # Demographic data
‚îÇ   ‚îú‚îÄ‚îÄ academic_data.csv  # Academic performance
‚îÇ   ‚îú‚îÄ‚îÄ lifestyle_data.csv # Lifestyle factors
‚îÇ   ‚îî‚îÄ‚îÄ mental_health.csv  # Mental health outcomes
‚îú‚îÄ‚îÄ PROJECT_STRUCTURE.md   # Development guidelines
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îî‚îÄ‚îÄ README.md             # This file
```

### Data Storage Options

The project supports **dual data storage modes**:

1. **Local Storage**: Traditional file-based approach using the `data/` directory
2. **Google Cloud Storage**: Cloud-based storage for scalable data access
3. **Hybrid Mode**: Seamlessly switch between local and cloud storage

#### Data Loading Configuration

The notebook includes a **configuration switch** that automatically handles data source selection:

```python
# Simple toggle for data source
USE_GCS = False  # Use local files
USE_GCS = True   # Use Google Cloud Storage
```

### Key Algorithms Implemented

- **Logistic Regression**: Binary classification for depression prediction
- **Linear Regression**: Continuous target prediction for CGPA
- **K-Means Clustering**: Unsupervised student segmentation
- **FPGrowth**: Association rule mining for pattern discovery

## ü§ù Contributing

This project demonstrates advanced data science and machine learning capabilities. Contributions are welcome in the following areas:

- **Model Enhancement**: Advanced algorithms and ensemble methods
- **Feature Engineering**: Novel feature extraction techniques
- **Visualization**: Interactive dashboards and reporting
- **Deployment**: Production-ready applications

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üë®üèæ‚Äçüíª Author

**David Araba**

- **Student ID**: 48093143
- **Course**: INFS3208 - Cloud Computing
- **Institution**: University of Queensland
- **Specialization**: Big Data Analytics, Machine Learning, Cloud Computing

## üèÜ Recognition

This project showcases expertise in:

- **Distributed Computing**: Apache Spark and PySpark
- **Machine Learning**: Multi-algorithm implementation
- **Data Science**: End-to-end analytics pipeline
- **Mental Health Analytics**: Domain-specific insights
- **Scalable Architecture**: Production-ready design

---

> **"Transforming student mental health through the power of big data and machine learning. Every insight discovered is a potential life saved."**

**‚≠ê Star this repository if you find it valuable for advancing mental health analytics!**
